{
    "conservative": {
      "learning_rate": 1e-5,
      "per_device_train_batch_size": 8,
      "num_train_epochs": 3,
      "warmup_ratio": 0.1,
      "weight_decay": 0.01,
      "gradient_accumulation_steps": 2,
      "description": "Lower learning rate, smaller batches, more stable"
    },
    "balanced": {
      "learning_rate": 2e-5,
      "per_device_train_batch_size": 16,
      "num_train_epochs": 2,
      "warmup_ratio": 0.06,
      "weight_decay": 0.01,
      "gradient_accumulation_steps": 1,
      "description": "Standard BERT fine-tuning parameters"
    },
    "aggressive": {
      "learning_rate": 5e-5,
      "per_device_train_batch_size": 32,
      "num_train_epochs": 1,
      "warmup_ratio": 0.05,
      "weight_decay": 0.001,
      "gradient_accumulation_steps": 1,
      "description": "Higher learning rate, faster training"
    }
  }